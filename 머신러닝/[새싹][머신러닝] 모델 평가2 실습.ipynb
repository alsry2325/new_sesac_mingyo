{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝 - 모델 평가 Part2\n",
    "\n",
    "주제\n",
    "- 데이터 분할\n",
    "- K-Fold 교차 검증(Cross Validation)\n",
    "- 하이퍼 파라미터 튜닝(Hyperparameter Tuning)\n",
    "- 앙상블 학습(Ensemble Learning)\n",
    "- 랜덤 포레스트(RandomForest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예제 실습 - K-Fold 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.3 0.4 0.5 0.6] test: [0.1 0.2]\n",
      "train: [0.1 0.2 0.4 0.5] test: [0.3 0.6]\n",
      "train: [0.1 0.2 0.3 0.6] test: [0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6])\n",
    "kfold = KFold(n_splits=3,shuffle=True,random_state=42)\n",
    "\n",
    "#kfoild\n",
    "# 데이터 교차로 분할하기\n",
    "for train,test in kfold.split(data):\n",
    "    print(f\"train: {data[train]} test: {data[test]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예제 실습 - K-Fold 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "0.6948051948051948\n",
      "[0.68181818 0.69480519 0.75324675 0.75163399 0.68627451]\n",
      "0.7135557253204311\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터셋 읽기\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "print(df.shape)\n",
    "\n",
    "# feature, target(Outcome) 분리\n",
    "X = df.drop(\"Outcome\",axis=1)\n",
    "y = df[\"Outcome\"] # 당뇨병 여부 (0: 당뇨병 X, 1: 당뇨병 O)\n",
    "\n",
    "#1. Hold-out방법으로 KNN모델 평가해보기\n",
    "# 훈련/테스트 데이터 분할(8:2), stratify 옵션 추가\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    X,y,test_size=0.2, random_state=42,stratify=y\n",
    ")\n",
    "#stratify=y : 원본 타겟 변수의 각 클래스 비율을 훈련/테스트에도 각각 유사한 비율로 분할하기\n",
    "\n",
    "# K=3 기본 KNN 모델 생성 및 훈련 \n",
    "knn = KNeighborsClassifier(n_neighbors=3) # K=3\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "# 성능 평가\n",
    "y_pred = knn.predict(X_test)\n",
    "print(knn.score(X_test,y_test))\n",
    "#or accuracy_score(y_test,y_pred)\n",
    "# 교차 검증\n",
    "cv_scores = cross_val_score(knn,X,y,cv=5) \n",
    "##1.모델 2.x전체데이터 3. y 전체 데이터, cv =K Fold의  K값(분할 개수)\n",
    "#Scoring: 평기 기준 지표; (분류의 디폴트: accuracy)\n",
    "#cv_scores: 각 폴드에 대한 평가 점수들에 대한 결과 리스트\n",
    "print(cv_scores)\n",
    "print(np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예제 실습 - 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "{'n_neighbors': np.int64(12)}\n",
      "0.7736771957883513\n",
      "0.7012987012987013\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터셋 읽기\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "print(df.shape)\n",
    "\n",
    "# feature, target 분리\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome'] # 당뇨병 여부 (0: 당뇨병 X, 1: 당뇨병 O)\n",
    "\n",
    "# 훈련/테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#여기서 Train : 하이퍼 파라미터 찾기 및  모델 학습을 위함\n",
    "# 최종적으로 최적의 하이퍼 파라미터로  학습된 모델을 평가하기 위한 테스트 데이터\n",
    "\n",
    "knn = KNeighborsClassifier() #Base Model\n",
    "param_grid = {\"n_neighbors\":np.arange(1,25)} # 1~24 k를 탐색\n",
    "# 각 하이퍼 파라미터 마다의 시험하고자 하는 범위 (key:value = hyper:range)\n",
    "\n",
    "knn_gscv = GridSearchCV(knn,param_grid,cv =5)\n",
    "# 5-Fold로 교차검증하면서 튜닝\n",
    "knn_gscv.fit(X_train,y_train)\n",
    "print(knn_gscv.best_params_) \n",
    "# best_params_: 지정한 parm_grid에 대해 각 최적의  하이퍼 파라미터 값 변환\n",
    "print(knn_gscv.best_score_)\n",
    "#best_score_:Train 데이터 안에서 수행된 CV(교차검증) 평균 점수(Accuracy)\n",
    "\n",
    "best_model = knn_gscv.best_estimator_\n",
    "#best_estimator_ : 최적의 파라미터로 학습이 된 모델\n",
    "\n",
    "#최적의 하이퍼 파라미터를 갖는 모델로 성능 평가\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "\n",
    "\n",
    "# Base 모델 생성\n",
    "\n",
    "# 튜닝할 파라미터 범위 설정\n",
    "\n",
    "# 5-Fold CV와 GridSearch로 튜닝\n",
    "\n",
    "# 구해진 최적의 모델\n",
    "\n",
    "# 해당 모델로 예측 및 평가 진행\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예제 실습 - 성능 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기본 knn정확도 : 0.7012987012987013\n",
      "최적의 하이퍼 파라미터 :{'metric': 'minkowski', 'n_neighbors': 15, 'p': 1, 'weights': 'uniform'}\n",
      "교차 검증 최고 정확도 :0.7687724910035986\n",
      "최적 모델 정확도0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "X = df.drop(\"Outcome\", axis=1)\n",
    "y = df[\"Outcome\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "#Train : 하이퍼 파라미터 튜닝과 최적의 모델 학습을 위함\n",
    "#Test: 최적의 모델을 평가하기 위함\n",
    "\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)# 훈련 데이터 스케일링 \n",
    "X_test_scaled = scaler.transform(X_test) # 테스트  데이터 스케일링\n",
    "\n",
    "\n",
    "# 기본적인 모델 학습 \n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train_scaled,y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(f\"기본 knn정확도 : {accuracy_score(y_test,y_pred)}\")\n",
    "\n",
    "# 하이퍼 파라미터 조합\n",
    "param_grid = {\n",
    "    'n_neighbors': list(range(3, 31, 2)), # 홀수 k \n",
    "    'weights': ['uniform', 'distance'],   #uniforme(디폴트), distance : 가까운 이웃에 가중치\n",
    "    'metric': ['minkowski'],\n",
    "    'p': [1, 2]  # manhattan, euclidean\n",
    "}\n",
    "\n",
    "\n",
    "# Base Model 생성\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 튜닝 \n",
    "grid = GridSearchCV(\n",
    "    estimator=knn,  # 어떤 모델에 대해서 수행할 것인지 모델 객체\n",
    "    param_grid=param_grid, # 하이퍼파라미터 격자 조합\n",
    "    cv=5,             # 5-Fold 교차 검증\n",
    "    scoring=\"accuracy\"  # 평가 및 최적의 파라미터를 찾을 때의 기준 지표\n",
    ")\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"최적의 하이퍼 파라미터 :{grid.best_params_}\")\n",
    "print(f\"교차 검증 최고 정확도 :{grid.best_score_}\")\n",
    "# 얻은 최적의 모델\n",
    "best_model = grid.best_estimator_\n",
    "# 최적의 모델로 예측 및 평가 진행\n",
    "\n",
    "pred_best = best_model.predict(X_test_scaled)\n",
    "print(f\"최적 모델 정확도{accuracy_score(y_test,pred_best)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예제 실습 - 앙상블; 랜덤포레스트\n",
    "\n",
    "Iris 데이터셋으로 품종(Species)을 예측하는 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 데이터 불러오기 및 feature/target 분리\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target\n",
    "\n",
    "# 2. 훈련/테스트 데이터 분할(8:2, stratify)\n",
    "None\n",
    "\n",
    "# 3. 랜덤포레스트 모델 생성 및 학습\n",
    "# - n_estimators=200\n",
    "# - max_depth=None\n",
    "# - random_state=42\n",
    "model = None\n",
    "None\n",
    "\n",
    "# 4. 예측 및 평가\n",
    "pred = None\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(None, None))\n",
    "print(\"Classification Report:\", classification_report(None, None))\n",
    "\n",
    "# 5. Feature Importance 시각화\n",
    "importances = model.None # 중요도 가져오기\n",
    "features = X.columns\n",
    "\n",
    "# 컬럼별 중요도 점수 막대 그래프 시각화\n",
    "plt.bar(None, None)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Feature Importances (RandomForest Classifier)\")\n",
    "plt.show()\n",
    "\n",
    "# 6. GridSearchCV를 통한 하이퍼파라미터 튜닝\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2]\n",
    "}\n",
    "\n",
    "# GridSearch로 하이퍼 파라미터 튜닝하기\n",
    "# - CV: 5\n",
    "# - 성능 평가 지표 기준: 정확도\n",
    "grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    None,\n",
    "    cv=None,\n",
    "    scoring=None,\n",
    ")\n",
    "\n",
    "# 튜닝 수행하기\n",
    "grid.fit(None, None)\n",
    "\n",
    "# 최적의 파라미터들과 점수 출력\n",
    "print(\"Best Params:\", grid.None)\n",
    "print(\"Best CV Score:\", grid.None)\n",
    "\n",
    "# 7. 최적 모델로 다시 평가\n",
    "best_model = grid.None\n",
    "best_pred = best_model.None\n",
    "\n",
    "print(\"[Best Model Accuracy]:\", accuracy_score(None, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 타이타닉 생존자 예측\n",
    "\n",
    "요구사항\n",
    "\n",
    "1. titanic3.csv 데이터셋을 읽어옵니다.\n",
    "2. 결측치는 간단히 처리합니다.\n",
    "  - age : 평균 또는 중앙값으로 대체\n",
    "  - embarked : 최빈값으로 대체\n",
    "3. 사용할 feature는 다음과 같이 한다.\n",
    "  - pclass, sex, age, sibsp, parch, fare, embarked\n",
    "4. 범주형 변수(sex, embarked)는 OneHotEncoder로 처리한다.\n",
    "5. survived를 타깃으로,\n",
    "  - train_test_split(..., stratify=y, test_size=0.2)로 분할한다.\n",
    "6. RandomForestClassifier에 대해 아래 파라미터로 GridSearchCV를 수행한다.\n",
    "  - n_estimators: `[100, 200]`\n",
    "  - max_depth: `[None, 5, 10]`\n",
    "  - min_samples_split: `[2, 5]`\n",
    "  - cv=5, scoring='accuracy'\n",
    "7. 최적 모델에 대해 \n",
    "  - 교차 검증 평균 정확도, \n",
    "  - 테스트 세트 정확도를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. 데이터 불러오기\n",
    "df = pd.read_csv(\"titanic3.csv\")\n",
    "\n",
    "# 2. 결측치 처리\n",
    "df[\"age\"] = None\n",
    "df[\"embarked\"] = None\n",
    "\n",
    "# 3. feature와 target 분리\n",
    "features = [\"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"embarked\"]\n",
    "X = None\n",
    "y = None\n",
    "\n",
    "# 4. Stratified train/test 분할 (8:2)\n",
    "None\n",
    "\n",
    "# 5. 범주형 인코딩: get_dummies 사용\n",
    "#    - train에는 fit 개념으로 get_dummies\n",
    "#    - test는 같은 컬럼 구조로 맞춰줘야 함\n",
    "categorical_cols = [\"sex\", \"embarked\"]\n",
    "\n",
    "# 5-1. 훈련 데이터에 대한 인코딩 \n",
    "X_train_encoded = pd.get_dummies(\n",
    "    None,\n",
    "    columns=None,\n",
    "    drop_first=True  # 더미 변수 함정 방지를 위해 첫 카테고리 드롭\n",
    ")\n",
    "# 5-2. 테스트 데이터에 대한 인코딩\n",
    "X_test_encoded = pd.get_dummies(\n",
    "    None,\n",
    "    columns=None,\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "# train과 test의 컬럼(더미 변수)이 다를 수 있으므로, test를 train에 맞춰 재정렬\n",
    "X_test_encoded = X_test_encoded.reindex(\n",
    "    columns=X_train_encoded.columns,\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "\n",
    "# 6. RF + GridSearchCV (전처리 분리, 모델만 튜닝)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 6-1. 탐색할 최적의 하이퍼 파라미터 격자 정의\n",
    "param_grid = None\n",
    "\n",
    "# GridSearch 정의\n",
    "grid_search = GridSearchCV(\n",
    "    rf,\n",
    "    param_grid=None,\n",
    "    cv=None,\n",
    "    scoring=None,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 튜닝 수행하기\n",
    "grid_search.fit(None, None)\n",
    "\n",
    "print(f\"최적 하이퍼파라미터: {grid_search.None}\")\n",
    "print(f\"최적 CV 평균 정확도: {grid_search.None:.4f}\")\n",
    "\n",
    "# 최적의 튜닝된 모델 가져오기\n",
    "best_model = None\n",
    "\n",
    "# 7. 테스트 세트 평가\n",
    "y_pred = best_model.None\n",
    "\n",
    "test_acc = accuracy_score(None, None)\n",
    "print(f\"테스트 정확도: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 은행 정기예금 가입 예측\n",
    "\n",
    "은행에서는 고객의 신규 정기예금 가입 여부(y)를 예측하고자 한다.\n",
    "예측 대상은 0 = 가입 X / 1 = 가입 O 이다.\n",
    "\n",
    "| 컬럼       | 설명          |\n",
    "| -------- | ----------- |\n",
    "| age      | 나이          |\n",
    "| job      | 직업          |\n",
    "| marital  | 결혼 여부       |\n",
    "| balance  | 잔고          |\n",
    "| duration | 통화 시간       |\n",
    "| campaign | 캠페인 연락 횟수   |\n",
    "| deposit  | 목표 변수 (0/1) |\n",
    "\n",
    "1. 데이터 불러오기 및 기초 확인\n",
    "  - bank.csv 읽기\n",
    "2. 범주형 인코딩\n",
    "  - job, marital → pd.get_dummies(drop_first=True)\n",
    "  - 이진 데이터는 그대로 사용\n",
    "3. 스케일링\n",
    "  - StandardScaler:\n",
    "  - age, balance, duration, campaign 적용\n",
    "4. 훈련/테스트 데이터 분할\n",
    "  - stratify=y\n",
    "  - test_size=0.2\n",
    "5. 기본 모델: Logistic Regression\n",
    "  - 학습\n",
    "  - Accuracy, F1-score 출력\n",
    "6. 교차검증\n",
    "  - 5-Fold\n",
    "  - scoring = \"accuracy\"\n",
    "7. GridSearchCV (KNN 대상)\n",
    "  - 튜닝할 파라미터:\n",
    "    ```\n",
    "    \n",
    "        \"n_neighbors\": [3,5,7,9,11],\n",
    "        \"weights\": [\"uniform\",\"distance\"],\n",
    "        \"metric\": [\"euclidean\",\"manhattan\"]\n",
    "    \n",
    "    ```\n",
    "  - 5-Fold CV\n",
    "  - scoring=\"accuracy\"\n",
    "  - 최적 파라미터 & 성능 출력\n",
    "8. Confusion Matrix + ROC Curve 시각화\n",
    "  - heatmap\n",
    "  - ROC curve & AUC 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 1. 데이터 셋을 읽고, 데이터 구조 파악\n",
    "df = None\n",
    "df = df[['age', 'job', 'marital', 'balance', 'duration', 'campaign', 'deposit']] # 일부 feature들만 활용\n",
    "\n",
    "print(df.head(), df.info(), df.isnull().sum())\n",
    "\n",
    "# 2. 인코딩\n",
    "df = pd.None(df, columns=[\"job\",\"marital\"], drop_first=True)\n",
    "\n",
    "# 3. 수치형 컬럼에 대한 스케일링\n",
    "scale_cols = [\"age\",\"balance\",\"duration\",\"campaign\"]\n",
    "\n",
    "scaler = None\n",
    "df[None] = scaler.None(df[None])\n",
    "\n",
    "# 4. 분할 (target: deposit)\n",
    "X = None\n",
    "y = df[None].map({'no' : 0, 'yes' : 1})\n",
    "\n",
    "# 4-1. 훈련/테스트 분할 (8:2), stratify\n",
    "None\n",
    "# 5. Logistic Regression 학습 및 성능 평가 진행\n",
    "lr = None(max_iter=2000)\n",
    "lr.fit(None,None)\n",
    "pred_lr = lr.predict(None)\n",
    "\n",
    "print(\"LR Accuracy:\",accuracy_score(None,None))\n",
    "print(\"LR F1:\",f1_score(None,None))\n",
    "\n",
    "# 6. 교차검증 - CV\n",
    "# - cv: 5\n",
    "# - 성능 평가 지표 기준: 정확도\n",
    "cv_scores = None\n",
    "print(\"CV scores:\",None)\n",
    "print(\"CV Mean:\",None)\n",
    "\n",
    "# 7. KNN과 GridSearchCV으로 하이퍼 파라미터 튜닝 수행\n",
    "param_grid = None\n",
    "\n",
    "# Base Model\n",
    "knn = KNeighborsClassifier()\n",
    "# GridSearch 생성 및 튜닝 수행\n",
    "# - cv: 5\n",
    "# - 성능 평가 지표 기준: 정확도\n",
    "grid = None\n",
    "None\n",
    "\n",
    "print(\"Best Params:\",grid.None)\n",
    "print(\"Best CV Score:\",grid.None)\n",
    "\n",
    "# 8. Confusion Matrix\n",
    "# 8-1. 최적의 모델 가져오고 예측 수행\n",
    "best_knn = None\n",
    "pred_knn = None\n",
    "# 8-2. 혼동 행렬 생성\n",
    "cm = None\n",
    "\n",
    "# 8-3. 혼동 행렬 히트맵으로 시각화\n",
    "None\n",
    "plt.show()\n",
    "\n",
    "# 9. ROC Curve\n",
    "# 9-1. 최적의 모델로 예측 확률 중에서 양성(1)일 확률만 추출\n",
    "proba = None\n",
    "# 9-2. roc_curve 생성하기\n",
    "fpr, tpr, thresholds = None\n",
    "\n",
    "# # 9-3. ROC-Curve 시각화하기\n",
    "plt.plot(None,None)\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"KNN ROC Curve\")\n",
    "plt.show()\n",
    "\n",
    "# 9-4. ROC-AUC 점수 출력\n",
    "print(\"KNN AUC:\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac_kernel",
   "language": "python",
   "name": "sesac_mingyo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
